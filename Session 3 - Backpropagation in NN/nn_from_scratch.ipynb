{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "911dae06-d967-45e5-afde-ff00761e6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09133cf8-90f1-4695-a669-fb05f8501f4d",
   "metadata": {},
   "source": [
    "### Part 1: Import the Housing data and do feature transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7efcf68-b2ca-4cb8-8c11-490ca1a745d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1340</td>\n",
       "      <td>313000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>3650</td>\n",
       "      <td>2384000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1930</td>\n",
       "      <td>342000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1940</td>\n",
       "      <td>550000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms  sqft_living    price\n",
       "0         3         1340   313000\n",
       "1         5         3650  2384000\n",
       "2         3         1930   342000\n",
       "3         3         2000   420000\n",
       "4         4         1940   550000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('house_price_full.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85fd63b2-defd-4ba3-b042-9afc73d18a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy()\n",
    "# Remove target\n",
    "Y = X.pop('price')\n",
    "\n",
    "# perform a scaler transform of the input data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# perform log transformation of target variable (For Sandeep: Is this needed?)\n",
    "Y = np.log(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95196b58-d932-456a-aa16-f9763822259f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.433198</td>\n",
       "      <td>-0.753258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.675735</td>\n",
       "      <td>1.457330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.433198</td>\n",
       "      <td>-0.188649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.433198</td>\n",
       "      <td>-0.121661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.621269</td>\n",
       "      <td>-0.179079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.621269</td>\n",
       "      <td>0.873582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1.675735</td>\n",
       "      <td>2.299459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>-0.433198</td>\n",
       "      <td>-0.724549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>-0.433198</td>\n",
       "      <td>-0.179079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>-0.433198</td>\n",
       "      <td>-1.040347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1\n",
       "0   -0.433198 -0.753258\n",
       "1    1.675735  1.457330\n",
       "2   -0.433198 -0.188649\n",
       "3   -0.433198 -0.121661\n",
       "4    0.621269 -0.179079\n",
       "..        ...       ...\n",
       "494  0.621269  0.873582\n",
       "495  1.675735  2.299459\n",
       "496 -0.433198 -0.724549\n",
       "497 -0.433198 -0.179079\n",
       "498 -0.433198 -1.040347\n",
       "\n",
       "[499 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled = pd.DataFrame(X)\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4059a87f-e14b-462c-8fc2-0d8171cea2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      12.653958\n",
       "1      14.684290\n",
       "2      12.742566\n",
       "3      12.948010\n",
       "4      13.217674\n",
       "         ...    \n",
       "494    13.380102\n",
       "495    13.764217\n",
       "496    12.128111\n",
       "497    12.721886\n",
       "498    12.254863\n",
       "Name: price, Length: 499, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c6c4da9-aa2b-46a2-acaa-cb900ac2b024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking 1 sample: x0,x1\n",
    "x1, x2 = df_scaled.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd37b5c7-9e4c-4919-ba3a-3718132eddf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-28 16:15:59.169774: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-28 16:15:59.170350: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.43319765, -0.7532575 ]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[x1,x2]], dtype=tf.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c919a12a-a45a-4cdb-b359-f75127de1f0b",
   "metadata": {},
   "source": [
    "### Part2: Forward Propagation with a single Neuron\n",
    "\n",
    "The simplest way to describe a neural network is that we have some inputs , which get combined into an auxilliary variable . The auxilliary variable is passed through the activation function  and the result is the output.\n",
    "\n",
    "Here is another image showing each step.\n",
    "![](neuron.png)\n",
    "Notice that the inputs are linearly combined according to some weights  and a bias . This transformation is also sometimes called an affine transformation. The perceptron transforms the weighted inputs according to the rule of the activation function. For a single perceptron, the output  is just the output from the perceptron. The linear transformation and activation of the neuron occurs within a single layer of the network (shown in the dotted box).\n",
    "\n",
    "Let's see what the single-layer, single neuron network give us. We have a couple of choices to make:\n",
    "\n",
    "We must choose some weights and some biases\n",
    "We must choose an activation function\n",
    "For now, we will manually specify the weights and biases.\n",
    "\n",
    "We choose a sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d22f12ae-177d-43ba-8afa-62e62afe6bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights\n",
    "w1 = tf.Variable([0.2], dtype=tf.float32)\n",
    "w2 = tf.Variable([0.15], dtype=tf.float32)\n",
    "#bias\n",
    "b = tf.Variable([0.1], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2e7b9c3-4f70-46dc-a6bc-b75a83803e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output from the first neuron is tf.Tensor([0.4751135], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Cumulative input\n",
    "z = b + w1*x1 +w2*x2\n",
    "h = tf.math.sigmoid(z)\n",
    "print(\"The output from the first neuron is\",h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34f3985-fe07-439f-a6ef-4b6ffbba1f1c",
   "metadata": {},
   "source": [
    "### Part3: Forward Propagation with multiple neurons\n",
    "\n",
    "![](multiple_neurons.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a708032a-8898-4c75-8a6b-19708e5db798",
   "metadata": {},
   "outputs": [],
   "source": [
    "## layer1 weights\n",
    "# neuron1\n",
    "b1 = tf.Variable([0.1])\n",
    "w11 = tf.Variable([0.2])\n",
    "w12 = tf.Variable([0.15])\n",
    "#neuron2\n",
    "b2 = tf.Variable([0.25])\n",
    "w21 = tf.Variable([0.5])\n",
    "w22 = tf.Variable([0.6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df953e00-859b-4559-94c9-9ac7b128fa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output from the first neuron is tf.Tensor([0.4751135], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## forward pass\n",
    "# neuron 1\n",
    "z1 = b1+w11*x1+w12*x2\n",
    "h1 = tf.math.sigmoid(z1)\n",
    "print(\"The output from the first neuron is\",h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "383503a1-fdcf-4f53-a0ee-03077dd6f5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output from the second neuron is tf.Tensor([0.39686298], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## forward pass\n",
    "# neuron 2\n",
    "z2 = b2+w21*x1+w22*x2\n",
    "h2 = tf.math.sigmoid(z2)\n",
    "print(\"The output from the second neuron is\",h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3156f647-fd4f-4f6a-aa6c-158dfd7f1e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## layer2 weights\n",
    "b1 = tf.Variable([0.4])\n",
    "w11 = tf.Variable([0.3])\n",
    "w12 = tf.Variable([0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81be3f6c-a1bd-42d3-9576-c325f90804b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output from the first neuron is tf.Tensor([0.62190664], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## forward pass\n",
    "# second layer\n",
    "z1 = b1+w11*h1+w12*h2\n",
    "h1 = z1\n",
    "print(\"The output from the first neuron is\",h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2668ce90-6f54-4f40-9bbe-ea6f0db4bff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = Y[0]\n",
    "y_pred = h1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "320dc2df-3489-4cb8-aa27-3162426357ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE error is [72.38514]\n"
     ]
    }
   ],
   "source": [
    "#loss\n",
    "L = 0.5*(y_true - y_pred)**2\n",
    "print(\"The MSE error is\",L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8442d282-5547-46e2-8a9d-d5769bb99dab",
   "metadata": {},
   "source": [
    "## Part 4: Forward pass matrix multiplication\n",
    "![](multiple_neurons.png)\n",
    "\n",
    "![](Matrix.gif)\n",
    "\n",
    "This network can be described as follows:\n",
    "\n",
    "- Input vector = $X = (x1,x2)$\n",
    "- Weight Matrix (hidden layer) = $$W^1 = \\begin{bmatrix}\n",
    "w^1_{11}&&w^1_{12}\\\\\n",
    "w^1_{21}&&w^1_{22}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "*note the subscripts are being mapped to weights in the figure\n",
    "\n",
    "- Bias/offset Matrix (hidden layer) = $$\n",
    "B^1_0 = \\begin{bmatrix}\n",
    "b^1_{1}\\\\\n",
    "b^1_{2}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Now the forward pass for the hidden layer can be described as \n",
    "\n",
    "$$W^1 \\times X^T + B^1_0= Z^1 = \\begin{bmatrix}\n",
    "z^1_{1}\\\\\n",
    "z^1_{2}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Applying the activation function $f$ over the matrix $Z$ will complete the forward pass.\n",
    "\n",
    "$$f(W^1 \\times X^T + B^1_0)= f(Z^1) = f(\\begin{bmatrix}\n",
    "z^1_{1}\\\\\n",
    "z^1_{2}\\\\\n",
    "\\end{bmatrix}) = \n",
    "\\begin{bmatrix}\n",
    "f(z^1_{1})\\\\\n",
    "f(z^1_{2})\\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "h^1_1\\\\\n",
    "h^1_2\\\\\n",
    "\\end{bmatrix}\n",
    "= H^1\n",
    "$$\n",
    "\n",
    "For the output layer:\n",
    "\n",
    "- The weight matrix is $$W^2 = \\begin{bmatrix}\n",
    "w^2_{11}&&w^2_{12}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- The bias/offset matrix is $$B^2_0 = \\begin{bmatrix}\n",
    "b^2_{1}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Now the forward pass can be written as:\n",
    "\n",
    "\n",
    "$$ B_0^2+W^2 \\times H^1$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21fab65a-f968-421e-80fa-86cb280685c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## layer 1 weights\n",
    "W1 = tf.Variable([[0.2, 0.15],\n",
    "                     [0.5, 0.6]], dtype=tf.float32)\n",
    "## layer 1 bias\n",
    "B1 = tf.Variable([[0.1],\n",
    "                [0.25]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f3cc3e1-574a-47dc-84c4-d66bf18b35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## layer 2 weights\n",
    "W2 = tf.Variable([[0.3, 0.2]], dtype=tf.float32)\n",
    "#bias\n",
    "B2 = tf.Variable([0.4], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "095a917a-2901-4dd5-9ca2-80c0d997a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data\n",
    "X = tf.constant([[x1,x2]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00f72506-52a9-43d5-9a06-5ebb270891bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.4751135 ]\n",
      " [0.39686298]], shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## forward pass layer 1\n",
    "Z1 = tf.matmul(W1, tf.transpose(X)) + B1\n",
    "H1 = tf.math.sigmoid(Z1)\n",
    "print(H1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "028e2e88-6417-47a1-9cee-ddb4f2b874f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## forward pass layer 2\n",
    "Z2 = tf.matmul(W2,H1)+B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e00bbaa-8b6f-4e6a-b43d-fc0a851e7739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.62190664]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ffd39a5-e9eb-47b5-9ac7-925c16acd3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72.38514]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = Z2.numpy()\n",
    "loss = 0.5*(y_true-y_pred)**2\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d35c31e-38e1-4c4f-aae9-6862e38063a8",
   "metadata": {},
   "source": [
    "## Part5: Random Weight Initialization\n",
    "\n",
    "![](multiple_neurons.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4f13145-94d3-40c3-a010-b5085660bfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_init_params():\n",
    "    w1 = tf.Variable(tf.random.uniform((2, 2)))\n",
    "    b1 = tf.Variable(tf.random.uniform((1, 2)))\n",
    "    w2 = tf.Variable(tf.random.uniform((2, 1)))\n",
    "    b2 = tf.Variable(tf.random.uniform((1, 1)))\n",
    "    return w1,b1,w2,b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d62f7eab-49b0-4594-b5b4-37e6088c9a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[x1,x2]], dtype=tf.float32)\n",
    "y = Y[0]\n",
    "w1,b1,w2,b2 = random_init_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27c5870a-6e1f-41e7-a90b-5fa693b81df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the initial 1st layer weights are:\n",
      " [[0.23209727 0.01658845]\n",
      " [0.83517206 0.99959767]]\n",
      "--------------------------------------------------\n",
      " the initial 2nd layer weights are:\n",
      " [[0.23209727]\n",
      " [0.01658845]]\n",
      "--------------------------------------------------\n",
      " the initial 1st layer bias are:\n",
      " [[0.23209727 0.01658845]]\n",
      "--------------------------------------------------\n",
      " the initial 2nd layer bias are:\n",
      " [[0.23209727]]\n"
     ]
    }
   ],
   "source": [
    "print(\" the initial 1st layer weights are:\\n\",w1.numpy())\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\" the initial 2nd layer weights are:\\n\",w2.numpy())\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\" the initial 1st layer bias are:\\n\",b1.numpy())\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\" the initial 2nd layer bias are:\\n\",b2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab9abe7a-f3d9-49bb-be50-bb38a51a1700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(x, w1, b1, w2, b2):\n",
    "    z1 = tf.matmul(x,w1) + b1\n",
    "    h1 = tf.math.sigmoid(z1)\n",
    "    z2 = tf.matmul(h1,w2) + b2\n",
    "    h2 = z2\n",
    "    return h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f29e7996-476d-429d-9af4-59205bf21db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE error is tf.Tensor([[75.99908]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "y_pred = forward_prop(x, w1, b1, w2, b2)\n",
    "#loss\n",
    "L = 0.5*(y - y_pred)**2\n",
    "print(\"The MSE error is\",L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844f9c21-ff86-4767-8d91-1d6a399789c1",
   "metadata": {},
   "source": [
    "## Part6: Backpropagation\n",
    "\n",
    "Find the value of x that minimises $y = x^2+4x$\n",
    "\n",
    "Gradient descent update equation\n",
    "\n",
    "$x_{new} := x_{old}-\\eta\\frac{dy}{dx}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "423c86c8-bf03-495e-8972-e69247822584",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(0.0) ## add gradient tape\n",
    "lr = eta = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98fe645c-fb0e-4257-84e0-9a47b3a81b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    y = x**2+4*x\n",
    "grad = tape.gradient(y,x) ## dy/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "529b973d-6a0d-424b-9b19-3c44b3e05672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad.numpy() #dy/dx = 2x+4, x=0 => dy/dx = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f9b9642-3290-41a6-a4ce-eeb20b412594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=-0.4>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.assign_sub(lr*grad) ## x_new = x_old -lr*dy/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76ffc91d-4154-40d4-8c8e-f46a76c3847f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca154ab8-599c-4ca6-8254-ad4f7fe8a472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4\n",
      "-0.72\n",
      "-0.9760001\n",
      "-1.1808001\n",
      "-1.34464\n",
      "-1.4757121\n",
      "-1.5805696\n",
      "-1.6644558\n",
      "-1.7315646\n",
      "-1.7852517\n"
     ]
    }
   ],
   "source": [
    "## full loop\n",
    "x = tf.Variable(0.0) ## add gradient tape\n",
    "lr = eta = 0.1\n",
    "for i in range(10):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y = x**2+4*x\n",
    "    grad = tape.gradient(y,x)\n",
    "    x.assign_sub(lr*grad)\n",
    "    print(x.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25dc73f-f2e2-47e9-be8a-495ca52658e3",
   "metadata": {},
   "source": [
    "\n",
    "![](gradients.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6797e506-2b65-4a8d-8f5c-24defd7411a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[x1,x2]], dtype=tf.float32)\n",
    "y = Y[0]\n",
    "\n",
    "def random_init_params():\n",
    "    w1 = tf.Variable(tf.random.uniform((2, 2)))\n",
    "    b1 = tf.Variable(tf.random.uniform((1, 2)))\n",
    "    w2 = tf.Variable(tf.random.uniform((2, 1)))\n",
    "    b2 = tf.Variable(tf.random.uniform((1, 1)))\n",
    "    return w1,b1,w2,b2\n",
    "\n",
    "def forward_prop(x, w1, b1, w2, b2):\n",
    "    z1 = tf.matmul(x,w1) + b1\n",
    "    h1 = tf.math.sigmoid(z1)\n",
    "    z2 = tf.matmul(h1,w2) + b2\n",
    "    h2 = z2\n",
    "    return h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0dd8c3e-473b-4a06-be20-b4230d0fc027",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1,b1,w2,b2 = random_init_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66195d4a-d966-4ecd-977f-678177f8b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    y_pred = forward_prop(x,w1,b1,w2,b2)\n",
    "    loss = 0.5*(y-y_pred)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a83bfbc-f1ba-4ca9-bfb4-cb8b5aa6fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "gw1, gb1, gw2, gb2 = tape.gradient(loss, [w1, b1, w2, b2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1e63266-99eb-4650-9034-0ce23e0beb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.2914811 , 0.01934897],\n",
       "       [0.50683635, 0.03364459]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gw1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b202f6b6-99e4-457e-8c9e-3abb11840bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.6728594 , -0.04466546]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "95600402-76fa-44b5-9d05-9e71c4ebbb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[-4.661717 ],\n",
       "       [-3.9726682]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "880ad697-3224-4527-ad47-84eb6ae09815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-12.328753]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d34744a-69df-45c8-a158-00c128f42a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of w1 before gradient update is <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[0.23209727, 0.01658845],\n",
      "       [0.83517206, 0.99959767]], dtype=float32)>\n",
      "Value of w1 after gradient update is <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[0.22918245, 0.01639496],\n",
      "       [0.8301037 , 0.9992612 ]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "lr=0.01\n",
    "print(f\"Value of w1 before gradient update is {w1}\")\n",
    "w1.assign_sub(lr*gw1)\n",
    "print(f\"Value of w1 after gradient update is {w1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe8bb25d-b7aa-4bd7-9765-28731e5944d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of b1 before gradient update is <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[0.23209727, 0.01658845]], dtype=float32)>\n",
      "Value of w1 after gradient update is <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[0.23882586, 0.0170351 ]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "lr=0.01\n",
    "print(f\"Value of b1 before gradient update is {b1}\")\n",
    "b1.assign_sub(lr*gb1)\n",
    "print(f\"Value of w1 after gradient update is {b1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "809b9b9e-acea-48dd-8386-c40eb3b20a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y, w1, b1, w2, b2):\n",
    "    y_true = y\n",
    "    with tf.GradientTape() as g:\n",
    "        y_pred = forward_prop(x, w1, b1, w2, b2)\n",
    "\n",
    "        # loss\n",
    "        loss = 0.5*(y_true - y_pred)** 2\n",
    "    \n",
    "    #Gradient calculation  \n",
    "    print(\"**************************************************\")\n",
    "    print(\"GRADIENTS\")\n",
    "    print(\"**************************************************\")\n",
    "    gw1, gb1, gw2, gb2 = g.gradient(loss, [w1, b1, w2, b2])\n",
    "    print(\" the gradient for 1st layer weights are:\\n\",gw1.numpy())\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\" the gradient for 2nd layer weights are:\\n\",gw2.numpy())\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\" the gradient for 1st layer bias are:\\n\",gb1.numpy())\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\" the gradient for 2nd layer bias are:\\n\",gb2.numpy())\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    # Gradient descent:\n",
    "    lr=0.2\n",
    "    w1.assign_sub(lr*gw1)\n",
    "    b1.assign_sub(lr*gb1) \n",
    "    w2.assign_sub(lr*gw2)\n",
    "    b2.assign_sub(lr*gb2)\n",
    "    print(\"**************************************************\")\n",
    "    print(\"NEW UPDATES\")\n",
    "    print(\"**************************************************\")\n",
    "    print(\" the updated 1st layer weights are:\\n\",w1.numpy())\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\" the updated 2nd layer weights are:\\n\",w2.numpy())\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\" the updated 1st layer bias are:\\n\",b1.numpy())\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\" the updated 2nd layer bias are:\\n\",b2.numpy())\n",
    "\n",
    "\n",
    "    return w1, b1, w2, b2,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c176262-1ea8-447b-b714-c30041457cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "GRADIENTS\n",
      "**************************************************\n",
      " the gradient for 1st layer weights are:\n",
      " [[0.2914811  0.01934897]\n",
      " [0.50683635 0.03364459]]\n",
      "--------------------------------------------------\n",
      " the gradient for 2nd layer weights are:\n",
      " [[-4.661717 ]\n",
      " [-3.9726682]]\n",
      "--------------------------------------------------\n",
      " the gradient for 1st layer bias are:\n",
      " [[-0.6728594  -0.04466546]]\n",
      "--------------------------------------------------\n",
      " the gradient for 2nd layer bias are:\n",
      " [[-12.328753]]\n",
      "--------------------------------------------------\n",
      "**************************************************\n",
      "NEW UPDATES\n",
      "**************************************************\n",
      " the updated 1st layer weights are:\n",
      " [[0.17380105 0.01271866]\n",
      " [0.73380476 0.9928687 ]]\n",
      "--------------------------------------------------\n",
      " the updated 2nd layer weights are:\n",
      " [[1.1644406]\n",
      " [0.8111221]]\n",
      "--------------------------------------------------\n",
      " the updated 1st layer bias are:\n",
      " [[0.36666915 0.02552154]]\n",
      "--------------------------------------------------\n",
      " the updated 2nd layer bias are:\n",
      " [[2.6978478]]\n"
     ]
    }
   ],
   "source": [
    "w1,b1,w2,b2 = random_init_params()\n",
    "w1, b1, w2, b2,loss = train(x, y, w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c8d3c6-de91-4a19-926a-6bd7b85720b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
